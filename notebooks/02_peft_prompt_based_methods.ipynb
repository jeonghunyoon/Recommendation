{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030258cb-d9bf-45fa-9327-0d5e9b23bb44",
   "metadata": {},
   "source": [
    "- https://huggingface.co/docs/peft/main/en/quicktour\n",
    "- Prompting\n",
    "  - Prompt tuning : https://huggingface.co/docs/peft/main/en/task_guides/clm-prompt-tuning\n",
    "  - Prefix tuning : https://huggingface.co/docs/peft/main/en/task_guides/seq2seq-prefix-tuning\n",
    "  - P-tuning : https://huggingface.co/docs/peft/main/en/task_guides/ptuning-seq-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be68f1-e89e-4615-8a93-8742a57b6b57",
   "metadata": {},
   "source": [
    "# Prompt tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9a0db03c-e2d9-4fbb-a4aa-54ac61256d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "711dbd66-c4fa-4040-9cf8-d727e984c7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer, \n",
    "    LlamaForCausalLM, \n",
    "    LlamaTokenizer, \n",
    "    default_data_collator,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_config, \n",
    "    get_peft_model, \n",
    "    PromptTuningInit, \n",
    "    PromptTuningConfig,\n",
    "    PrefixTuningConfig,\n",
    "    PromptEncoderConfig,\n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    PeftType\n",
    ")\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab0175-591f-4f9f-9f10-fa96d100a828",
   "metadata": {},
   "source": [
    "## * Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f923ede2-e420-4f38-a515-74a7253af637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:3\"\n",
    "my_root_directory=\"\"\n",
    "root_path = f\"{my_root_directory}/llm/model_output/\"\n",
    "\n",
    "# https://huggingface.co/bigscience/bloomz-560m\n",
    "model_name_or_path = \"bigscience/bloomz-560m\"\n",
    "# model_name_or_path = f\"{my_root_directory}/llm/llama/llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a8a1a05d-1858-47ee-8e1c-6e8926f7a9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.CAUSAL_LM,\n",
    "#     inference_mode=False, \n",
    "#     r=8, \n",
    "#     lora_alpha=32, \n",
    "#     lora_dropout=0.1\n",
    "# )\n",
    "\n",
    "# For the best results, \n",
    "# the prompt_tuning_init_text should have the same number of tokens that should be predicted.\n",
    "# To do this, \n",
    "# you can set num_virtual_tokens to the number of tokens of the prompt_tuning_init_text :\n",
    "prompt_tuning_init_text=\"Classify if the tweet is a complaint or not:\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "    num_virtual_tokens=len(tokenizer(prompt_tuning_init_text)[\"input_ids\"]),\n",
    "    prompt_tuning_init_text=prompt_tuning_init_text,\n",
    "    tokenizer_name_or_path=model_name_or_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabf923-8eaf-4708-83af-84c1a7a5bf36",
   "metadata": {},
   "source": [
    "## * Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e8e604-1af8-4f9b-8401-cbd860310f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"twitter_complaints\"\n",
    "checkpoint_name = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}_v1.pt\".replace(\n",
    "    \"/\", \"_\"\n",
    ")\n",
    "text_column = \"Tweet text\"\n",
    "label_column = \"text_label\"\n",
    "max_length = 64\n",
    "lr = 3e-2\n",
    "num_epochs = 50\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9000649-22ad-4547-b34f-d0ae9d3d2905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset raft (/home/irteam/.cache/huggingface/datasets/ought___raft/twitter_complaints/1.1.0/79c4de1312c1e3730043f7db07179c914f48403101f7124e2fe336f6f54d9f84)\n",
      "100%|██████████| 2/2 [00:00<00:00, 307.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/ought/raft\n",
    "dataset = load_dataset(\"ought/raft\", dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c56bfa4-5ee3-4f8b-acfe-66c0c97e3074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['Tweet text', 'ID', 'Label'], 'test': ['Tweet text', 'ID', 'Label']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66f8234d-08be-4c22-9d7c-e314a1768a85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Tweet text', 'ID', 'Label'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f6e6f9-ca1a-482b-a897-0376cf4cf656",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Tweet text', 'ID', 'Label'],\n",
       "    num_rows: 3399\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff77f438-cea2-466b-a09c-9193a1548bad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tweet text': '@HMRCcustomers No this is my first job', 'ID': 0, 'Label': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3146f0-617e-4969-8e5b-06585af96d24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/irteam/.cache/huggingface/datasets/ought___raft/twitter_complaints/1.1.0/79c4de1312c1e3730043f7db07179c914f48403101f7124e2fe336f6f54d9f84/cache-083b7bfcf2ab7905.arrow\n",
      "Loading cached processed dataset at /home/irteam/.cache/huggingface/datasets/ought___raft/twitter_complaints/1.1.0/79c4de1312c1e3730043f7db07179c914f48403101f7124e2fe336f6f54d9f84/cache-18b457bd4e4c4ea0.arrow\n"
     ]
    }
   ],
   "source": [
    "classes = [k.replace(\"_\", \" \") for k in dataset[\"train\"].features[\"Label\"].names]\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [classes[label] for label in x[\"Label\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f519095-f0f6-4589-baa2-bdb1d5ae4094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tweet text': '@HMRCcustomers No this is my first job',\n",
       " 'ID': 0,\n",
       " 'Label': 2,\n",
       " 'text_label': 'no complaint'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "94261d0a-b3cb-4e9e-8d4f-13be0f862775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "507064ec-bfa3-44ad-a7c9-589f0cd41729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f27f436-ade4-4dca-bedf-02c65f811e53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "target_max_length = max([len(tokenizer(class_label)[\"input_ids\"]) for class_label in classes])\n",
    "print(target_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e16b8ece-6fef-48e5-9602-4dd799651468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3074, 4762, 60943], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c749072-325f-42bb-a9bc-7caafe91033a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    batch_size = len(examples[text_column])\n",
    "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
    "    targets = [str(x) for x in examples[label_column]]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(targets)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.pad_token_id]\n",
    "        # print(i, sample_input_ids, label_input_ids)\n",
    "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "    # print(model_inputs)\n",
    "    # print(labels)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i]\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + model_inputs[\"attention_mask\"][i]\n",
    "        labels[\"input_ids\"][i] = [-100] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + label_input_ids\n",
    "        # if i in [0, 1]:\n",
    "        #     print(model_inputs[\"input_ids\"][i])\n",
    "        #     print(model_inputs[\"attention_mask\"][i])\n",
    "        #     print(labels[\"input_ids\"][i])\n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad9ac383-5fdf-4e75-ba1c-9e75e162467b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_input_data = preprocess_function(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bccc39e6-029e-4078-82d8-4d547e3990ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tweet text', 'ID', 'Label', 'text_label']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10164b1b-583a-4eea-a564-9ff5b0492248",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    }
   ],
   "source": [
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1cbb93-7f21-42f9-9681-2a1a4b78f5c7",
   "metadata": {},
   "source": [
    "## * DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0cfa59e-d42d-47c8-9e64-20dffe51d697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = processed_datasets[\"train\"]\n",
    "eval_dataset = processed_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27bcf1fd-dc33-49d3-b940-bb88e43a6a42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d041c49-40dc-4c3e-a7ca-e9db74f084c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edab7dc-0b41-4596-b16a-5e99aad9f4c5",
   "metadata": {},
   "source": [
    "## * Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b902c31-0ef5-441a-9ca2-c8b18ab90233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "# model = LlamaForCausalLM.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaf4b3db-63dc-408b-ad3b-544e125b429c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8192 || all params: 559222784 || trainable%: 0.0014648902430985358\n"
     ]
    }
   ],
   "source": [
    "# model과 config를 wrapping\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddfc190c-a30f-423e-b520-db264c93bb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tweet text : @nationalgridus I have no water and the bill is current and paid. Can you do something about this? Label :  NoThe present invention relates to a method of']\n"
     ]
    }
   ],
   "source": [
    "# Before prompt tuning\n",
    "\n",
    "inputs = tokenizer(\n",
    "    f'{text_column} : {\"@nationalgridus I have no water and the bill is current and paid. Can you do something about this?\"} Label : ',\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    # generate 호출\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_new_tokens=10, eos_token_id=3\n",
    "    )\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9707144a-3863-4589-8674-230cf42840b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "138cb0fe-c7ab-4a45-8486-7181e39ff13f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  6.90it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_ppl: 3.380147851886592e+17, train_epoch_loss: 40.36186599731445, eval_ppl: 16679.0, eval_epoch_loss: 9.721905708312988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_ppl: 538404.0, train_epoch_loss: 13.196364402770996, eval_ppl: 13381.1865234375, eval_epoch_loss: 9.501605033874512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train_ppl: 284034.09375, train_epoch_loss: 12.556849479675293, eval_ppl: 9123.810546875, eval_epoch_loss: 9.118642807006836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.18it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train_ppl: 121827.3984375, train_epoch_loss: 11.710360527038574, eval_ppl: 5693.92333984375, eval_epoch_loss: 8.647154808044434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.26it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train_ppl: 21584.353515625, train_epoch_loss: 9.979723930358887, eval_ppl: 3951.930908203125, eval_epoch_loss: 8.281959533691406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, train_ppl: 4086.43310546875, train_epoch_loss: 8.315427780151367, eval_ppl: 6859.73193359375, eval_epoch_loss: 8.833423614501953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train_ppl: 878.7350463867188, train_epoch_loss: 6.7784833908081055, eval_ppl: 13165.3671875, eval_epoch_loss: 9.485344886779785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.26it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, train_ppl: 261.6167907714844, train_epoch_loss: 5.566880702972412, eval_ppl: 19448.931640625, eval_epoch_loss: 9.875547409057617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, train_ppl: 147.39532470703125, train_epoch_loss: 4.9931182861328125, eval_ppl: 17187.388671875, eval_epoch_loss: 9.751931190490723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, train_ppl: 104.95393371582031, train_epoch_loss: 4.653521537780762, eval_ppl: 26680.7109375, eval_epoch_loss: 10.191696166992188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train_ppl: 81.39569854736328, train_epoch_loss: 4.399322509765625, eval_ppl: 33229.58203125, eval_epoch_loss: 10.411195755004883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.26it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, train_ppl: 67.08550262451172, train_epoch_loss: 4.205967903137207, eval_ppl: 48844.83203125, eval_epoch_loss: 10.796403884887695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.31it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, train_ppl: 53.68946075439453, train_epoch_loss: 3.9832167625427246, eval_ppl: 59047.09765625, eval_epoch_loss: 10.986090660095215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, train_ppl: 43.468894958496094, train_epoch_loss: 3.772045612335205, eval_ppl: 83257.5234375, eval_epoch_loss: 11.329693794250488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, train_ppl: 38.822174072265625, train_epoch_loss: 3.658991575241089, eval_ppl: 86719.3125, eval_epoch_loss: 11.370431900024414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, train_ppl: 29.82989501953125, train_epoch_loss: 3.3955111503601074, eval_ppl: 121658.234375, eval_epoch_loss: 11.70897102355957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, train_ppl: 23.94160270690918, train_epoch_loss: 3.1756176948547363, eval_ppl: 286042.65625, eval_epoch_loss: 12.563896179199219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.18it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, train_ppl: 18.19940948486328, train_epoch_loss: 2.9013891220092773, eval_ppl: 554802.25, eval_epoch_loss: 13.226366996765137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, train_ppl: 14.414392471313477, train_epoch_loss: 2.668227195739746, eval_ppl: 711650.1875, eval_epoch_loss: 13.475341796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, train_ppl: 11.717874526977539, train_epoch_loss: 2.4611153602600098, eval_ppl: 1778658.25, eval_epoch_loss: 14.391369819641113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, train_ppl: 11.812820434570312, train_epoch_loss: 2.4691853523254395, eval_ppl: 825788.5, eval_epoch_loss: 13.624094009399414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, train_ppl: 8.01941204071045, train_epoch_loss: 2.081865072250366, eval_ppl: 1308490.625, eval_epoch_loss: 14.08438491821289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, train_ppl: 6.380003452301025, train_epoch_loss: 1.8531686067581177, eval_ppl: 1455277.5, eval_epoch_loss: 14.190707206726074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23, train_ppl: 5.108733177185059, train_epoch_loss: 1.6309514045715332, eval_ppl: 1851730.375, eval_epoch_loss: 14.431631088256836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24, train_ppl: 3.9735682010650635, train_epoch_loss: 1.3796645402908325, eval_ppl: 2006133.375, eval_epoch_loss: 14.511719703674316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25, train_ppl: 3.627457618713379, train_epoch_loss: 1.288532018661499, eval_ppl: 963477.1875, eval_epoch_loss: 13.778304100036621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26, train_ppl: 2.8793156147003174, train_epoch_loss: 1.0575525760650635, eval_ppl: 2760612.75, eval_epoch_loss: 14.830963134765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.26it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27, train_ppl: 2.9725444316864014, train_epoch_loss: 1.0894182920455933, eval_ppl: 1459396.875, eval_epoch_loss: 14.193533897399902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28, train_ppl: 2.3122549057006836, train_epoch_loss: 0.8382232189178467, eval_ppl: 1980808.875, eval_epoch_loss: 14.499015808105469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.26it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29, train_ppl: 1.8611103296279907, train_epoch_loss: 0.6211733222007751, eval_ppl: 1943938.375, eval_epoch_loss: 14.480226516723633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.24it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30, train_ppl: 1.8047007322311401, train_epoch_loss: 0.5903947353363037, eval_ppl: 1572628.625, eval_epoch_loss: 14.268259048461914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31, train_ppl: 1.675833821296692, train_epoch_loss: 0.5163108110427856, eval_ppl: 1104459.25, eval_epoch_loss: 13.91486644744873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32, train_ppl: 1.6426419019699097, train_epoch_loss: 0.4963058531284332, eval_ppl: 1383934.375, eval_epoch_loss: 14.140440940856934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33, train_ppl: 1.6532964706420898, train_epoch_loss: 0.5027711391448975, eval_ppl: 1149193.25, eval_epoch_loss: 13.954570770263672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34, train_ppl: 1.5835336446762085, train_epoch_loss: 0.45965877175331116, eval_ppl: 911221.125, eval_epoch_loss: 13.722540855407715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35, train_ppl: 1.4889373779296875, train_epoch_loss: 0.39806264638900757, eval_ppl: 1150890.0, eval_epoch_loss: 13.956046104431152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.25it/s]\n",
      "100%|██████████| 425/425 [00:30<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36, train_ppl: 1.4481050968170166, train_epoch_loss: 0.37025585770606995, eval_ppl: 721718.5, eval_epoch_loss: 13.48939037322998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37, train_ppl: 1.5175349712371826, train_epoch_loss: 0.41708728671073914, eval_ppl: 1019304.3125, eval_epoch_loss: 13.834630966186523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.26it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38, train_ppl: 1.5402865409851074, train_epoch_loss: 0.43196845054626465, eval_ppl: 798447.5, eval_epoch_loss: 13.590424537658691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.25it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39, train_ppl: 1.3242266178131104, train_epoch_loss: 0.2808285355567932, eval_ppl: 862893.0, eval_epoch_loss: 13.668045997619629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40, train_ppl: 1.2781380414962769, train_epoch_loss: 0.24540437757968903, eval_ppl: 1085222.875, eval_epoch_loss: 13.897295951843262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41, train_ppl: 1.270923137664795, train_epoch_loss: 0.23974347114562988, eval_ppl: 1156074.5, eval_epoch_loss: 13.960540771484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42, train_ppl: 1.2374060153961182, train_epoch_loss: 0.21301725506782532, eval_ppl: 1096227.125, eval_epoch_loss: 13.907384872436523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:30<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43, train_ppl: 1.2273577451705933, train_epoch_loss: 0.20486363768577576, eval_ppl: 1292886.25, eval_epoch_loss: 14.0723876953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44, train_ppl: 1.2194174528121948, train_epoch_loss: 0.1983732134103775, eval_ppl: 1372642.0, eval_epoch_loss: 14.132247924804688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.26it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45, train_ppl: 1.1868008375167847, train_epoch_loss: 0.17126137018203735, eval_ppl: 1172581.25, eval_epoch_loss: 13.97471809387207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.27it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46, train_ppl: 1.1878573894500732, train_epoch_loss: 0.17215116322040558, eval_ppl: 1166293.5, eval_epoch_loss: 13.969341278076172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.29it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47, train_ppl: 1.1761916875839233, train_epoch_loss: 0.16228191554546356, eval_ppl: 1250548.75, eval_epoch_loss: 14.039093017578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.28it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48, train_ppl: 1.1723730564117432, train_epoch_loss: 0.15902996063232422, eval_ppl: 1266396.875, eval_epoch_loss: 14.05168628692627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.26it/s]\n",
      "100%|██████████| 425/425 [00:29<00:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49, train_ppl: 1.1648969650268555, train_epoch_loss: 0.1526326984167099, eval_ppl: 1270319.5, eval_epoch_loss: 14.054779052734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # 굳이 items?\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"epoch: {epoch}, train_ppl: {train_ppl}, train_epoch_loss: {train_epoch_loss}, eval_ppl: {eval_ppl}, eval_epoch_loss: {eval_epoch_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407a082-c4df-476a-9f67-451b9b12ba58",
   "metadata": {},
   "source": [
    "## * Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8906d82f-840f-4102-ba0d-e39f16529409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(\n",
    "#     f'{text_column} : {\"@nationalgridus I have no water and the bill is current and paid. Can you do something about this?\"} Label : ',\n",
    "#     return_tensors=\"pt\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e75230cf-e966-4559-afee-47648200354b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tweet text : @nationalgridus I have no water and the bill is current and paid. Can you do something about this? Label : complaint']\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    # generate 호출\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_new_tokens=10, eos_token_id=3\n",
    "    )\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573c2d5-a07b-4ecf-b358-f02c9181b1a7",
   "metadata": {},
   "source": [
    "# Prifix tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1972140-479c-43de-86d0-a0e73e7f7a22",
   "metadata": {},
   "source": [
    "## * Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32f3aac9-dddb-4e3d-a009-e6489294eba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/google-t5/t5-large\n",
    "# (Text-To-Text-Transfer Transformer - T5)\n",
    "model_name_or_path = \"t5-large\"\n",
    "\n",
    "text_column = \"sentence\"\n",
    "label_column = \"text_label\"\n",
    "max_length = 128\n",
    "lr = 1e-2\n",
    "num_epochs = 5\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d43fc504-ed30-4011-bfc1-976e123a3050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_config = PrefixTuningConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM, \n",
    "    inference_mode=False, \n",
    "    num_virtual_tokens=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c685b-48fe-446b-b989-c07c821c29fb",
   "metadata": {},
   "source": [
    "## * Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930200a-ae8d-4e66-a2c6-c9536e617b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"sentences_allagree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b55b72b-5e2e-4681-8fde-287f9c96f281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.04k/6.04k [00:00<00:00, 7.82MB/s]\n",
      "Downloading readme: 100%|██████████| 8.88k/8.88k [00:00<00:00, 8.35MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset financial_phrasebank/sentences_allagree to /home/irteam/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 682k/682k [00:00<00:00, 31.3MB/s]\n",
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset financial_phrasebank downloaded and prepared to /home/irteam/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 315.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/takala/financial_phrasebank\n",
    "dataset = load_dataset(\"financial_phrasebank\", dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50986fd3-9f79-4ce6-a53f-f0536c6fd82e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 2264\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset에 train만 존재\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32569514-dd78-4fef-8650-0ed502adffd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f858de9e-4899-42b7-9de9-52a53d246074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 2037\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 227\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cc1eadb-d042-4419-8cab-f15b12524c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[\"validation\"] = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0f96969-6a29-43f2-98e9-ca454d54c1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 2037\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 227\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 227\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ebc9788-b97f-40d0-a527-2ab8c426d7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1e2d618-afeb-43ca-8c98-513b6b52b009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 2037\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 227\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f1c22ea-d79e-48cf-b629-4ee1ca818a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'neutral', 'positive']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = dataset[\"train\"].features[\"label\"].names\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3df348bc-929a-4731-91e6-4773bd046388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'The company is studying the feasibility of focusing most of its processed meat production in the Vantaa facilities and the processing of fresh meat in the Forssa facilities .',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48710d26-c255-4e45-a140-cba60a347425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [classes[label] for label in x[\"label\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69f468da-d3d9-466f-9de3-18a841d72bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'The company is studying the feasibility of focusing most of its processed meat production in the Vantaa facilities and the processing of fresh meat in the Forssa facilities .',\n",
       " 'label': 1,\n",
       " 'text_label': 'neutral'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab462fc0-b4a8-44f9-baa7-deef5cfc39d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 181kB/s]\n",
      "Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 1.14MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.39M/1.39M [00:00<00:00, 2.66MB/s]\n",
      "/home/irteam/.local/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5_fast.py:165: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0de260f0-eee7-4f78-8bb5-fc9fbc1d0243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples[text_column]\n",
    "    targets = examples[label_column]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = tokenizer(targets, max_length=2, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = labels[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f7c3ae5-9316-4a35-8ccc-39bab49631b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    }
   ],
   "source": [
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33b1a979-8b37-44f4-a9bb-5a09624066c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2037\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 227\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e6520cb-7ad1-4623-a2e1-9defa855c860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = processed_datasets[\"train\"]\n",
    "eval_dataset = processed_datasets[\"validation\"]\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663711d-55d6-47bd-8259-b0697164f0b1",
   "metadata": {},
   "source": [
    "## * Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec31a3a7-961a-4bec-ae0b-7e79a0f18b04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 2.95G/2.95G [05:51<00:00, 8.40MB/s]\n",
      "Downloading generation_config.json: 100%|██████████| 147/147 [00:00<00:00, 13.2kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ead6758b-9faa-4e0f-b2e3-8c20e4b12e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 983040 || all params: 738651136 || trainable%: 0.13308583065659835\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73bacb81-6e6f-4405-9a67-eb5b9d73dcf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    \"The Lithuanian beer market made up 14.41 million liters in January , a rise of 0.8 percent from the year-earlier figure , the Lithuanian Brewers ' Association reporting citing the results from its members .\",\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5622362a-57ad-46f5-9e03-6b377a019fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the Association of Lithuanian Brewers ']\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed964506-9274-46ec-b16a-c147faca651d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cc43b5f4-20d9-4046-af2f-df6b0dab5405",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:44<00:00,  5.76it/s]\n",
      "100%|██████████| 29/29 [00:02<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_ppl: 1.0080, train_epoch_loss: 0.0080, eval_ppl: 1.0730, eval_epoch_loss: 0.0705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:44<00:00,  5.76it/s]\n",
      "100%|██████████| 29/29 [00:02<00:00, 11.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_ppl: 1.0077, train_epoch_loss: 0.0076, eval_ppl: 1.0695, eval_epoch_loss: 0.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:44<00:00,  5.77it/s]\n",
      "100%|██████████| 29/29 [00:02<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train_ppl: 1.0044, train_epoch_loss: 0.0044, eval_ppl: 1.0391, eval_epoch_loss: 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:44<00:00,  5.69it/s]\n",
      "100%|██████████| 29/29 [00:02<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train_ppl: 1.0047, train_epoch_loss: 0.0047, eval_ppl: 1.0420, eval_epoch_loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:44<00:00,  5.73it/s]\n",
      "100%|██████████| 29/29 [00:02<00:00, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train_ppl: 1.0053, train_epoch_loss: 0.0053, eval_ppl: 1.0473, eval_epoch_loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "    \n",
    "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = eval_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"epoch: {epoch}, train_ppl: {train_ppl:.4f}, train_epoch_loss: {train_epoch_loss:.4f}, eval_ppl: {eval_ppl:.4f}, eval_epoch_loss: {eval_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "560fb065-121a-404c-b586-a890f65873ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.0352422907489 % on the evaluation dataset\n",
      "['neutral', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive']\n",
      "['neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive']\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for pred, true in zip(eval_preds, dataset[\"validation\"][\"text_label\"]):\n",
    "    if pred.strip() == true.strip():\n",
    "        correct += 1\n",
    "    total += 1\n",
    "accuracy = correct / total * 100\n",
    "print(f\"accuracy: {accuracy} % on the evaluation dataset\")\n",
    "print(f\"{eval_preds[:10]}\")\n",
    "print(f\"{dataset['validation']['text_label'][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab060369-7b0a-40cf-a06b-3567104f1cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692eff7-5a21-4e36-bb23-b057b54602cf",
   "metadata": {},
   "source": [
    "# P-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a438b-8f1a-46c9-b7d4-2fe63aeb278c",
   "metadata": {},
   "source": [
    "## * Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f76209c-b1c6-4564-bf11-c587f4c961ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"bigscience/bloomz-560m\"\n",
    "task = \"mrpc\"\n",
    "num_epochs = 20\n",
    "lr = 1e-3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9ea44087-51c9-4f1b-b370-5ac7ae992f97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 316/316 [00:00<00:00, 856kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/SetFit--mrpc to /home/irteam/.cache/huggingface/datasets/SetFit___json/SetFit--mrpc-cf983d02a5b947c7/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/1.14M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   6%|▌         | 66.6k/1.14M [00:00<00:02, 406kB/s]\u001b[A\n",
      "Downloading data:  20%|█▉        | 224k/1.14M [00:00<00:01, 719kB/s] \u001b[A\n",
      "Downloading data: 100%|██████████| 1.14M/1.14M [00:00<00:00, 2.17MB/s][A\n",
      "Downloading data files:  33%|███▎      | 1/3 [00:01<00:02,  1.03s/it]\n",
      "Downloading data:   0%|          | 0.00/127k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 127k/127k [00:00<00:00, 725kB/s] \u001b[A\n",
      "Downloading data files:  67%|██████▋   | 2/3 [00:01<00:00,  1.26it/s]\n",
      "Downloading data:   0%|          | 0.00/533k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  10%|▉         | 51.2k/533k [00:00<00:01, 302kB/s]\u001b[A\n",
      "Downloading data:  31%|███       | 165k/533k [00:00<00:00, 508kB/s] \u001b[A\n",
      "Downloading data: 100%|██████████| 533k/533k [00:00<00:00, 1.01MB/s][A\n",
      "Downloading data files: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 1062.93it/s]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/irteam/.cache/huggingface/datasets/SetFit___json/SetFit--mrpc-cf983d02a5b947c7/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 541.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/nyu-mll/glue\n",
    "dataset = load_dataset(\"SetFit/mrpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225302b-aab1-49b4-a294-12850c8881cc",
   "metadata": {},
   "source": [
    "## * Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5fa6acbf-5d71-450c-8e0e-0283bc936d24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67abdf26-df2a-4301-8b6a-a982c470d622",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'text2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0,\n",
       " 'label_text': 'equivalent'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "de2aec5e-5f05-4722-9d8a-bf6107555429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 4.47MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy =  evaluate.load(\"accuracy\")\n",
    "# accuracy.compute(predictions=[0, 1, 1, 0], references=[0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8a04e0a7-1771-460c-96f5-9e646b8adda0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.75k/5.75k [00:00<00:00, 6.50MB/s]\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"glue\", task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e0b601c9-abcd-42cc-a7d1-9e6541e9d1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Return dict or None:\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8489539c-96c3-4a92-913a-757a69cca869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_size=\"left\")\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1436381b-a141-476b-8814-a98f71612366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    outputs = tokenizer(examples[\"text1\"], examples[\"text2\"], truncation=True, max_length=None)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "86079168-ecd5-48a9-9601-d0dd3778e03e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [15144, 350, 3786, 41939, 3868, 44163, 630, 43944, 1683, 9487, 567, 368, 53134, 567, 630, 461, 188210, 4396, 656, 386, 3868, 27602, 503, 76110, 35414, 427, 6371, 661, 3804, 567, 368, 53134, 567, 630, 2883, 350, 3786, 41939, 3868, 44163, 461, 188210, 4396, 656, 386, 3868, 27602, 503], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_function(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5d7ba580-ec4a-4f5d-a593-b8c4e8550681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text1\", \"text2\", \"idx\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6a509161-2003-48b0-8dbe-8f6b5d38bc55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 1, 'label_text': 'equivalent', 'input_ids': [15144, 350, 3786, 41939, 3868, 44163, 630, 43944, 1683, 9487, 567, 368, 53134, 567, 630, 461, 188210, 4396, 656, 386, 3868, 27602, 503, 76110, 35414, 427, 6371, 661, 3804, 567, 368, 53134, 567, 630, 2883, 350, 3786, 41939, 3868, 44163, 461, 188210, 4396, 656, 386, 3868, 27602, 503], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(tokenized_datasets[\"train\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9bc947b8-304b-437b-af28-712cc4f6bb12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pad the examples in the batches to the longest sequence in the batch:\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58fc4c-20fd-4b23-9fcb-df89f872f33e",
   "metadata": {},
   "source": [
    "## * Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bb7d7720-5e85-4f28-a936-313499bd73e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# P-tuning uses a prompt encoder to optimize the prompt parameters:\n",
    "#   num_virtual_tokens is the number of virtual tokens to use, or in other words, the prompt\n",
    "peft_config = PromptEncoderConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    num_virtual_tokens=20,\n",
    "    encoder_hidden_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "da6dbb55-baab-44c3-8c05-a2dbe70aa1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloomz-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/irteam/.local/lib/python3.7/site-packages/peft/tuners/p_tuning.py:147: UserWarning: for MLP, the `encoder_num_layers` is ignored. Exactly 2 MLP layers are used.\n",
      "  f\"for {self.encoder_type}, the `encoder_num_layers` is ignored. Exactly 2 MLP layers are used.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 304384 || all params: 559518976 || trainable%: 0.054401014631539506\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)\n",
    "model = get_peft_model(model, peft_config).to(device)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "634ce7cf-2a35-4801-b174-fe40742dd0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BloomForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[42.1092, -5.3616]], device='cuda:3')\n",
      "not equivalent: 100%\n",
      "equivalent: 0%\n"
     ]
    }
   ],
   "source": [
    "# Before P-tuning\n",
    "classes = [\"not equivalent\", \"equivalent\"]\n",
    "\n",
    "sentence1 = \"Coast redwood trees are the tallest trees on the planet and can grow over 300 feet tall.\"\n",
    "sentence2 = \"The coast redwood trees, which can attain a height of over 300 feet, are the tallest trees on earth.\"\n",
    "\n",
    "inputs = tokenizer(sentence1, sentence2, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k,v in inputs.items()}\n",
    "    outputs = model(**inputs).logits\n",
    "    print(outputs)\n",
    "    \n",
    "paraphrased_text = torch.softmax(outputs, dim=1).tolist()[0]\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {int(round(paraphrased_text[i] * 100))}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9214c100-877d-4d25-85cc-c72594e56a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=root_path + \"/bloomz-peft-p-tuning\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8b253740-4439-4ece-9557-8f141b5f6d02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6569f2-df78-4d47-acff-a785c0886a9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "125865ee-b576-4d7d-9f67-51563f9b6cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "427ad224-b972-4aca-a896-ec9acbe58c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BloomForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-13.7025, -11.5503]], device='cuda:3')\n",
      "not equivalent: 10%\n",
      "equivalent: 90%\n"
     ]
    }
   ],
   "source": [
    "# After P-tuing :\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs).logits\n",
    "    print(outputs)\n",
    "    \n",
    "paraphrased_text = torch.softmax(outputs, dim=1).tolist()[0]\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {int(round(paraphrased_text[i] * 100))}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
